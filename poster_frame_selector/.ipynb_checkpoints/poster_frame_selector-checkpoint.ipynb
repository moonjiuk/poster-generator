{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55b5567-e796-446e-a068-7c62ae1fa9c7",
   "metadata": {},
   "source": [
    "# 포스터 프레임 선택\n",
    "##### movie.mp4에서 포스터로 가장 적절한 프레임을 5장을 선택하여 selected_frames폴더에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedf4e4-6192-4e1f-b41e-2500f093f321",
   "metadata": {},
   "source": [
    "## 1. 동영상을 일정 간격으로 자르고 각 프레임별 인물 신뢰도 측정\n",
    "##### OpenCV로 movie.mp4동영상 파일에서 일정간격으로 프레임을 선택한 후, 인물이 가장 잘 나온 프레임 5장을 selected_frames폴더에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e3c638-c6da-443c-9433-2830d129899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2ef809d-08e8-4715-aaed-304e06d28c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 25573, FPS: 23\n"
     ]
    }
   ],
   "source": [
    "# 설정\n",
    "video_path = \"movie.mp4\"  # 동영상 파일 경로\n",
    "output_folder = \"character_frames\"  # 중간 저장 폴더\n",
    "final_output_folder = \"selected_frames\"  # 최종 저장 폴더\n",
    "frame_interval = 300  # 프레임 추출 간격\n",
    "top_n = 5  # 상위 프레임 개수\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")  # YOLOv8 경량화 모델 사용\n",
    "\n",
    "# 동영상 정보\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"Total frames: {frame_count}, FPS: {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38eff901-6f63-4b14-b276-3a75ca1c513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 top frames saved to character_frames.\n"
     ]
    }
   ],
   "source": [
    "# 프레임 추출 및 신뢰도 계산, 알고리즘 개선으로 성능 향상 필요할듯\n",
    "frame_scores = []\n",
    "\n",
    "for count in range(0, frame_count, frame_interval):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, count)  # 특정 프레임으로 이동\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO로 인물(cls=0)의 신뢰도 계산\n",
    "    results = model.predict(frame, verbose=False)\n",
    "    scores = [obj[4].item() for obj in results[0].boxes.data if int(obj[5].item()) == 0]  # 인물만 필터링\n",
    "    max_score = max(scores) if scores else 0  # 가장 신뢰도가 높은 인물을 점수로 사용\n",
    "\n",
    "    # 점수 기록\n",
    "    frame_scores.append((count, frame, max_score))\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 상위 5개 프레임 선택\n",
    "frame_scores = sorted(frame_scores, key=lambda x: x[2], reverse=True)[:top_n]  # 점수 기준 정렬 후 상위 5개 선택\n",
    "\n",
    "# 상위 프레임 저장\n",
    "for frame_index, frame, score in frame_scores:\n",
    "    frame_path = os.path.join(output_folder, f\"frame_{frame_index}.jpg\")  # 프레임 번호를 파일명에 포함\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "\n",
    "print(f\"{len(frame_scores)} top frames saved to {output_folder}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2deb4a-ebe9-433e-914f-4d79224c6ace",
   "metadata": {},
   "source": [
    "## 2. 상위 5개 프레임의 앞뒤 분석 및 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b49c03e8-cd39-4aad-b8d2-10846cbacb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 final frames saved to selected_frames.\n"
     ]
    }
   ],
   "source": [
    "# 선명도 계산 함수\n",
    "def calculate_sharpness(frame):\n",
    "    \"\"\"\n",
    "    프레임의 선명도를 계산합니다.\n",
    "    Laplacian 변환의 분산을 사용하여 선명도를 측정.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 그레이스케일 변환\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()  # Laplacian 변환 후 분산 계산\n",
    "\n",
    "# 동영상 다시 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 최종 프레임 리스트\n",
    "final_frames = []\n",
    "\n",
    "\n",
    "for frame_index, frame, score in frame_scores:\n",
    "    sharpness_scores = [(frame_index, frame, calculate_sharpness(frame))]  # 현재 프레임의 선명도 계산\n",
    "\n",
    "    # 앞뒤 프레임 탐색\n",
    "    search_range = 30\n",
    "    for offset in [-search_range, search_range]:\n",
    "        neighbor_index = frame_index + offset\n",
    "        if 0 <= neighbor_index < frame_count:  # 유효한 범위 내의 프레임만 처리\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, neighbor_index)  # 해당 프레임으로 이동\n",
    "            ret, neighbor_frame = cap.read()\n",
    "            if ret:\n",
    "                sharpness = calculate_sharpness(neighbor_frame)  # 선명도 계산\n",
    "                sharpness_scores.append((neighbor_index, neighbor_frame, sharpness))\n",
    "\n",
    "    # 선명도가 가장 높은 프레임 선택\n",
    "    best_frame_index, best_frame, _ = max(sharpness_scores, key=lambda x: x[2])\n",
    "    final_frames.append((best_frame_index, best_frame))\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 최종 프레임 저장\n",
    "for i, (frame_index, frame) in enumerate(final_frames):\n",
    "    frame_path = os.path.join(final_output_folder, f\"frame_{frame_index}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "\n",
    "print(f\"{len(final_frames)} final frames saved to {final_output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdde380-4fe7-4df7-8b4b-e1a2d5fbb4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
